{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec59b4c8-8292-4897-9241-0e4db50fb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd586324-bf1a-4ab1-8c4d-7457867d4fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prade\\AppData\\Local\\Temp\\ipykernel_30492\\421393757.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  liverdata['Gender'] = liverdata['Gender'].replace({'Male': 1, 'Female': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65       0              0.7               0.1                   187   \n",
       "1   62       1             10.9               5.5                   699   \n",
       "2   62       1              7.3               4.1                   490   \n",
       "3   58       1              1.0               0.4                   182   \n",
       "4   72       1              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        1  \n",
       "1      3.2                        0.74        1  \n",
       "2      3.3                        0.89        1  \n",
       "3      3.4                        1.00        1  \n",
       "4      2.4                        0.40        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liverdata = pd.read_csv('C:\\\\projects\\\\liverdata\\\\indian_liver_patient.csv')\n",
    "liverdata['Gender'] = liverdata['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "#liverdata = liverdata.dropna()\n",
    "liverdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e52e21b-04d1-47e7-8abf-cf56a45fb819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         583 non-null    int64  \n",
      " 1   Gender                      583 non-null    int64  \n",
      " 2   Total_Bilirubin             583 non-null    float64\n",
      " 3   Direct_Bilirubin            583 non-null    float64\n",
      " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
      " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
      " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
      " 7   Total_Protiens              583 non-null    float64\n",
      " 8   Albumin                     583 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio  579 non-null    float64\n",
      " 10  Dataset                     583 non-null    int64  \n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 50.2 KB\n"
     ]
    }
   ],
   "source": [
    "liverdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b6a0ce-90a2-4733-92fb-6c1a755789c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset\n",
       "1    416\n",
       "2    167\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liverdata.groupby('Dataset').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc32950b-f910-4c84-a6fb-556790b2373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "Gender                        0\n",
       "Total_Bilirubin               0\n",
       "Direct_Bilirubin              0\n",
       "Alkaline_Phosphotase          0\n",
       "Alamine_Aminotransferase      0\n",
       "Aspartate_Aminotransferase    0\n",
       "Total_Protiens                0\n",
       "Albumin                       0\n",
       "Albumin_and_Globulin_Ratio    4\n",
       "Dataset                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liverdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb02ec-b004-4ceb-b790-5412e392b5e1",
   "metadata": {},
   "source": [
    "<h2>Step 2: Feature Engineering </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9d00e1-dc99-45b2-bc1f-0f7e0c248ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin',\n",
       "       'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\n",
       "       'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\n",
       "       'Albumin_and_Globulin_Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = liverdata.columns[:10]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa18d36-64ba-4c60-9177-1c7c3c799722",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liverdata[feature_names]\n",
    "Y = liverdata.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619fe4e-b26d-46ea-ba5d-ff83c7d0de33",
   "metadata": {},
   "source": [
    "<h2> Step 3: Data standardization </h2>\n",
    "\n",
    "<h4>Standardize features by removing the mean and scaling to unit variance.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ce50c0-1716-4e89-b9cb-7dd86f30054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features chosen based on RFECV result\n",
    "# best_features = ['Age', 'Gender', 'Direct_Bilirubin','Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Total_Protiens','Albumin_and_Globulin_Ratio']\n",
    "best_features = ['Age','Gender', 'Direct_Bilirubin','Alkaline_Phosphotase', 'Alamine_Aminotransferase', 'Albumin']\n",
    "\n",
    "X_mod = StandardScaler().fit_transform(X[best_features])\n",
    "y_mod = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f426039e-c453-4977-9fc1-b354b2836f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and testing (80% / 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_mod,\n",
    "    y_mod,\n",
    "    random_state=42,\n",
    "    test_size=0.20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf038d-ab6e-4441-b10b-4f2f8c4ce52c",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA)Â¶\n",
    "The main goal of a PCA analysis is to identify patterns in data. PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8298fb4e-9f17-48fe-b419-fba50705aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26460569 0.20469215]\n",
      "PCA sum: 46.93%\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print('PCA sum: {:.2f}%'.format(sum(pca.explained_variance_ratio_) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f5dec7-ff76-4769-b8d0-063e63d4681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Score: \n",
      " 68.88\n",
      "Logistic Regression Test Score: \n",
      " 70.09\n",
      "Accuracy: \n",
      " 0.7008547008547008\n",
      "Confusion Matrix: \n",
      " [[78  9]\n",
      " [26  4]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.90      0.82        87\n",
      "           2       0.31      0.13      0.19        30\n",
      "\n",
      "    accuracy                           0.70       117\n",
      "   macro avg       0.53      0.51      0.50       117\n",
      "weighted avg       0.64      0.70      0.66       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict Output\n",
    "log_predicted= logreg.predict(X_test)\n",
    "\n",
    "logreg_score = round(logreg.score(X_train, y_train) * 100, 2)\n",
    "logreg_score_test = round(logreg.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "# Equation coefficient and Intercept\n",
    "print('Logistic Regression Training Score: \\n', logreg_score)\n",
    "print('Logistic Regression Test Score: \\n', logreg_score_test)\n",
    "\n",
    "print('Accuracy: \\n', accuracy_score(y_test,log_predicted))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,log_predicted))\n",
    "print('Classification Report: \\n', classification_report(y_test,log_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb33dda-fe78-4a3e-8a8c-b8e36c8c592f",
   "metadata": {},
   "source": [
    "<H2> Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3aed6cb-774c-4444-9598-a077691f0ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: \n",
      " 100.0\n",
      "Random Forest Test Score: \n",
      " 78.63\n",
      "Accuracy: \n",
      " 0.7863247863247863\n",
      "[[78  9]\n",
      " [16 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.90      0.86        87\n",
      "           2       0.61      0.47      0.53        30\n",
      "\n",
      "    accuracy                           0.79       117\n",
      "   macro avg       0.72      0.68      0.70       117\n",
      "weighted avg       0.77      0.79      0.78       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "# Predict Output\n",
    "rf_predicted = random_forest.predict(X_test)\n",
    "\n",
    "random_forest_score = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "random_forest_score_test = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "print('Random Forest Score: \\n', random_forest_score)\n",
    "print('Random Forest Test Score: \\n', random_forest_score_test)\n",
    "print('Accuracy: \\n', accuracy_score(y_test,rf_predicted))\n",
    "print(confusion_matrix(y_test,rf_predicted))\n",
    "print(classification_report(y_test,rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1132ef8f-2895-4e66-9bda-9db58d1b4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters found:  {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Random Forest Test Score: \n",
      " 76.07\n",
      "Accuracy: \n",
      " 0.7606837606837606\n",
      "[[76 11]\n",
      " [17 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.87      0.84        87\n",
      "           2       0.54      0.43      0.48        30\n",
      "\n",
      "    accuracy                           0.76       117\n",
      "   macro avg       0.68      0.65      0.66       117\n",
      "weighted avg       0.75      0.76      0.75       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf_predicted = best_rf.predict(X_test)\n",
    "\n",
    "print('Best Random Forest Test Score: \\n', round(best_rf.score(X_test, y_test) * 100, 2))\n",
    "print('Accuracy: \\n', accuracy_score(y_test, best_rf_predicted))\n",
    "print(confusion_matrix(y_test, best_rf_predicted))\n",
    "print(classification_report(y_test, best_rf_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd651911-62fb-44b7-a6df-9a971e620408",
   "metadata": {},
   "source": [
    " <h2> Convolutional Neural Network (CNN) model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3164d6cb-d72a-4f31-82ea-1ef7c956242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c7174e1-d89b-4673-8a22-e65d2bb02052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prade\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 3, 2, 2, 2, 2, 2, 2, 10), output.shape=(None, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:554\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m     )\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m     )\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 3, 2, 2, 2, 2, 2, 2, 10), output.shape=(None, 10)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Ensure y_train and y_test are properly one-hot encoded\n",
    "num_classes = 10  # Update this to your actual number of classes\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Output layer should match the number of classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4fde9-b125-4af2-8f6b-24fdcfbbed5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
